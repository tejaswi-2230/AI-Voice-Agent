# ğŸ™ï¸ AI Voice Agent â€” Conversational Intelligence in Real Time

> Part of my **#30DaysOfVoiceAgents** challenge â€” building an end-to-end AI-powered voice assistant that feels natural, responsive, and production-ready.

---

## ğŸš€ Overview

This project is a **dual-mode Voice AI application**:
- **Voice Agent Assistant (Text-to-Speech)** â€” Type anything, choose a voice, and hear it instantly.
- **Conversational Voice Bot (LLM + TTS)** â€” Speak naturally, let the AI transcribe, think, and respond in a lifelike voice.

Itâ€™s designed with **speed, clarity, and engagement** in mind â€” from the **glassmorphic UI** to the **seamless speech pipeline**.

---

## âœ¨ Features

- ğŸ¤ **Single Smart Record Button** â€” Start/Stop recording with one tap, animated for intuitive feedback.
- â± **Live Recording Timer** â€” Shows how long youâ€™ve been speaking.
- ğŸ”Š **Auto-Playback** â€” AI responses play instantly without clicking.
- ğŸ§  **Full AI Pipeline**:
  1. Voice input (Browser Recording API)
  2. **AssemblyAI** â€” Real-time transcription
  3. **Google Gemini** â€” Conversational reasoning
  4. **Murf AI** â€” Human-like voice generation
- ğŸ¨ **Million-Dollar UI** â€” Glassmorphism, smooth animations, responsive design.

---

## ğŸ› ï¸ Tech Stack

**Frontend**
- HTML5, CSS3, JavaScript (Vanilla)
- CSS animations & glassmorphism design
- Audio Recording API

**Backend**
- **Flask** (`app01.py`) â€” Handles TTS generation
- **FastAPI** (`main.py`) â€” Handles full voice pipeline & file uploads
- **AssemblyAI** â€” Speech-to-text
- **Google Gemini** â€” LLM text generation
- **Murf AI** â€” Text-to-speech

**Other**
- `python-dotenv` for environment configuration
- `requests` for API calls
- `ffmpeg` for audio format handling (optional but recommended)

---

## ğŸ—ï¸ Architecture

[ Browser UI ]
| (audio/text)
v
[ Flask (TTS) ] ----> Murf AI API
[ FastAPI (LLM+Voice) ] ---> AssemblyAI ---> Gemini LLM ---> Murf AI

Both services can run in parallel, and the UI shows **both assistants side-by-side**.

---

## ğŸ“¦ Installation

1. **Clone the repo**  
git clone https://github.com/yourusername/voice-ai-agent.git  
cd voice-ai-agent

2. **Install dependencies**  
pip install -r requirements.txt

3. **Set environment variables**  
Create a `.env` file in the project root:

MURF_API_KEY=your_murf_api_key  
ASSEMBLYAI_API_KEY=your_assemblyai_key  
GEMINI_API_KEY=your_gemini_key

4. **(Optional) Ensure ffmpeg is installed**  
ffmpeg -version

---

## â–¶ï¸ Running the App

**Start Flask server (TTS Assistant)**  
python app01.py

**Start FastAPI server (LLM + Voice Bot)**  
uvicorn main:app --reload --port 8000

Open `index.html` in your browser (served via Flask static files).

---

## ğŸ”— API Endpoints

### POST /generate-audio  
Generate Murf TTS from given text.  

**Body (JSON):**  
{
  "text": "Hello world",
  "voiceId": "en-US-natalie",
  "format": "mp3"
}

---

### POST /upload-audio  
Upload recorded audio file.  

**Form-data:**  
- audio: audio file

---

### POST /agent/chat/{session_id}  
Complete voice pipeline:  
1. Audio â†’ AssemblyAI (transcription)  
2. Text â†’ Gemini (response)  
3. Response â†’ Murf AI (voice)  

**Returns:** transcription, LLM text, and audio file URL.

---

## ğŸ“¸ Screenshots

### Voice Agent Assistant (TTS)  
![TTS UI](docs/screenshots/tts_ui.png)

### Conversational Voice Bot  
![Voice Bot UI](docs/screenshots/voice_bot_ui.png)

---

## ğŸ’¡ My Flair â€” Why This Project Stands Out

- Designed for **real product feel**, not just a tutorial.  
- Instant feedback loop â€” no waiting, no manual steps.  
- **Modular architecture** â€” can swap out AI providers easily.  
- UI that **invites interaction** â€” this isnâ€™t your average dev console app.

---

## ğŸ† Credits

Built with â¤ï¸ during #30DaysOfVoiceAgents using:  
- [AssemblyAI](https://www.assemblyai.com/)  
- [Google Gemini](https://deepmind.google/)  
- [Murf AI](https://murf.ai/)
