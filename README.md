# üéôÔ∏è AI Voice Agent ‚Äî Conversational Intelligence in Real Time

> Part of my **#30DaysOfVoiceAgents** challenge ‚Äî building an end-to-end AI-powered voice assistant that feels natural, responsive, and production-ready.

---

## üöÄ Overview

This project is a **dual-mode Voice AI application**:
- **Voice Agent Assistant (Text-to-Speech)** ‚Äî Type anything, choose a voice, and hear it instantly.
- **Conversational Voice Bot (LLM + TTS)** ‚Äî Speak naturally, let the AI transcribe, think, and respond in a lifelike voice.

It‚Äôs designed with **speed, clarity, and engagement** in mind ‚Äî from the **glassmorphic UI** to the **seamless speech pipeline**.

---

## ‚ú® Features

- üé§ **Single Smart Record Button** ‚Äî Start/Stop recording with one tap, animated for intuitive feedback.
- ‚è± **Live Recording Timer** ‚Äî Shows how long you‚Äôve been speaking.
- üîä **Auto-Playback** ‚Äî AI responses play instantly without clicking.
- üß† **Full AI Pipeline**:
  1. Voice input (Browser Recording API)
  2. **AssemblyAI** ‚Äî Real-time transcription
  3. **Google Gemini** ‚Äî Conversational reasoning
  4. **Murf AI** ‚Äî Human-like voice generation
- üé® **Million-Dollar UI** ‚Äî Glassmorphism, smooth animations, responsive design.

---

## üõ†Ô∏è Tech Stack

**Frontend**
- HTML5, CSS3, JavaScript (Vanilla)
- CSS animations & glassmorphism design
- Audio Recording API

**Backend**
- **Flask** (`app01.py`) ‚Äî Handles TTS generation
- **FastAPI** (`main.py`) ‚Äî Handles full voice pipeline & file uploads
- **AssemblyAI** ‚Äî Speech-to-text
- **Google Gemini** ‚Äî LLM text generation
- **Murf AI** ‚Äî Text-to-speech

**Other**
- `python-dotenv` for environment configuration
- `requests` for API calls
- `ffmpeg` for audio format handling (optional but recommended)

---

## üèóÔ∏è Architecture

[ Browser UI ]
| (audio/text)
v
[ Flask (TTS) ] ----> Murf AI API
[ FastAPI (LLM+Voice) ] ---> AssemblyAI ---> Gemini LLM ---> Murf AI

Both services can run in parallel, and the UI shows **both assistants side-by-side**.

---

## üì¶ Installation

1. **Clone the repo**  
git clone https://github.com/yourusername/voice-ai-agent.git  
cd voice-ai-agent

2. **Install dependencies**  
pip install -r requirements.txt

3. **Set environment variables**  
Create a `.env` file in the project root:

MURF_API_KEY=your_murf_api_key  
ASSEMBLYAI_API_KEY=your_assemblyai_key  
GEMINI_API_KEY=your_gemini_key

4. **(Optional) Ensure ffmpeg is installed**  
ffmpeg -version

---

## ‚ñ∂Ô∏è Running the App

**Start Flask server (TTS Assistant)**  
python app01.py

**Start FastAPI server (LLM + Voice Bot)**  
uvicorn main:app --reload --port 8000

Open `index.html` in your browser (served via Flask static files).

---

## üîó API Endpoints

### POST /generate-audio  
Generate Murf TTS from given text.  

**Body (JSON):**  
{
  "text": "Hello world",
  "voiceId": "en-US-natalie",
  "format": "mp3"
}

---

### POST /upload-audio  
Upload recorded audio file.  

**Form-data:**  
- audio: audio file

---

### POST /agent/chat/{session_id}  
Complete voice pipeline:  
1. Audio ‚Üí AssemblyAI (transcription)  
2. Text ‚Üí Gemini (response)  
3. Response ‚Üí Murf AI (voice)  

**Returns:** transcription, LLM text, and audio file URL.

---

## Screenshots

### Voice Generator UI
![Voice Generator](images/voice_generator.png)

### Voice Agent LLM
![Voice Agent LLM](images/voice_agent_llm.png)

### FastAPI Backend
![FastAPI Backend](images/fastapi.png)

### TTS Recording
![TTS Recording](images/tts_recording.png)


---

## üí° My Flair ‚Äî Why This Project Stands Out

- Designed for **real product feel**, not just a tutorial.  
- Instant feedback loop ‚Äî no waiting, no manual steps.  
- **Modular architecture** ‚Äî can swap out AI providers easily.  
- UI that **invites interaction** ‚Äî this isn‚Äôt your average dev console app.

---

## üèÜ Credits

Built with ‚ù§Ô∏è during #30DaysOfVoiceAgents using:  
- [AssemblyAI](https://www.assemblyai.com/)  
- [Google Gemini](https://deepmind.google/)  
- [Murf AI](https://murf.ai/)
